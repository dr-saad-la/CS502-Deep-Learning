{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bb48a8-e474-4259-9f0f-f90206d132ee",
   "metadata": {},
   "source": [
    "# Understanding Long Short-Term Memory (LSTM) Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab8b7c-c539-4c46-b4af-ead4a4d535fd",
   "metadata": {},
   "source": [
    "## 1. The Challenge with Traditional RNNs\n",
    "\n",
    "Traditional Recurrent Neural Networks (RNNs) face significant challenges when dealing with long-term dependencies:\n",
    "\n",
    "- **Vanishing Gradient Problem**: As the sequence length grows, gradients tend to either vanish or explode during backpropagation through time\n",
    "- **Limited Memory Capacity**: Difficulty in retaining information from earlier timesteps\n",
    "- **Information Mixing**: Inability to effectively separate relevant historical information from recent inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c658d8-43b3-47cd-93df-55f16297dcf3",
   "metadata": {},
   "source": [
    "## 2. LSTM Architecture Overview\n",
    "\n",
    "### 2.1 Core Components\n",
    "\n",
    "1. **Cell State ($C_t$)**:\n",
    "   - Acts as a conveyor belt running through the entire sequence\n",
    "   - Allows information to flow through the network unchanged\n",
    "   - Protected and controlled by gates\n",
    "\n",
    "2. **Hidden State ($h_t$)**:\n",
    "   - Contains the output information for the current timestep\n",
    "   - Used for making predictions\n",
    "   - Filtered version of cell state\n",
    "\n",
    "### 2.2 Gates Structure\n",
    "\n",
    "LSTMs employ three gates to control information flow:\n",
    "\n",
    "1. **Forget Gate ($f_t$)**:\n",
    "   - Decides what information to discard from the cell state\n",
    "   - Uses a sigmoid function: output between 0 (forget) and 1 (keep)\n",
    "   - Formula: $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$\n",
    "\n",
    "2. **Input Gate ($i_t$)**:\n",
    "   - Controls what new information will be stored\n",
    "   - Consists of two parts:\n",
    "     * Sigmoid layer: decides which values to update\n",
    "     * Tanh layer: creates candidate values\n",
    "   - Formula: $i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$\n",
    "   - Candidate values: $\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$\n",
    "\n",
    "3. **Output Gate ($o_t$)**:\n",
    "   - Determines what parts of the cell state will be output\n",
    "   - Filters the cell state through tanh and gate control\n",
    "   - Formula: $o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2ea93-a655-468f-a780-7fda5bbe2fdf",
   "metadata": {},
   "source": [
    "## 3. Information Flow in LSTM\n",
    "\n",
    "### 3.1 Cell State Update\n",
    "\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "\n",
    "This equation shows how:\n",
    "- Old information is forgotten ($f_t \\odot C_{t-1}$)\n",
    "- New information is added ($i_t \\odot \\tilde{C}_t$)\n",
    "\n",
    "### 3.2 Hidden State Update\n",
    "\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "The output gate controls what information from the cell state becomes the hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7c9a0-72b8-4d79-9b6f-05f1abb9a3ea",
   "metadata": {},
   "source": [
    "## 4. Key Advantages of LSTM\n",
    "\n",
    "1. **Controlled Information Flow**:\n",
    "   - Explicit mechanisms for reading, writing, and erasing information\n",
    "   - Selective memory updates through gating mechanisms\n",
    "\n",
    "2. **Gradient Control**:\n",
    "   - Cell state provides uninterrupted gradient flow\n",
    "   - Helps mitigate vanishing/exploding gradients\n",
    "\n",
    "3. **Flexible Memory Duration**:\n",
    "   - Can learn both short-term and long-term dependencies\n",
    "   - Adaptive memory length based on the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8cc1a-4d9a-444c-8d7e-cbe1aeb567cd",
   "metadata": {},
   "source": [
    "## 5. Mathematical Foundation\n",
    "\n",
    "### 5.1 Complete LSTM Forward Pass\n",
    "\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
    "\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
    "\n",
    "$$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$\n",
    "\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$\n",
    "\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "Where:\n",
    "- $x_t$: Input at time t\n",
    "- $h_{t-1}$: Previous hidden state\n",
    "- $C_{t-1}$: Previous cell state\n",
    "- $W_f, W_i, W_C, W_o$: Weight matrices\n",
    "- $b_f, b_i, b_C, b_o$: Bias terms\n",
    "- $\\sigma$: Sigmoid function\n",
    "- $\\odot$: Element-wise multiplication\n",
    "\n",
    "## 6. Practical Considerations\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Cell state typically initialized to zeros\n",
    "   - Hidden state initialized to zeros\n",
    "   - Gates' weights initialized with small random values\n",
    "\n",
    "2. **Training Aspects**:\n",
    "   - Usually trained with backpropagation through time (BPTT)\n",
    "   - May require gradient clipping to prevent explosion\n",
    "   - Benefits from proper sequence padding and masking\n",
    "\n",
    "3. **Variants**:\n",
    "   - Peephole connections: Allow gates to look at cell state\n",
    "   - Coupled forget and input gates: Reduce parameters\n",
    "   - GRU: Simplified version with fewer gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd8277-0244-44aa-aef8-9431c0147a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
