{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521899c-f30a-4c79-b8be-9d1e19c4ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4587c5-9108-4738-8f2c-7be26123523a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext nb_js_diagrammers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfac766-bbfd-42e4-8020-2312be44c277",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdca4e98-b3b4-4267-b0c0-97eb1d039bdd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"&lt;html&gt;\n",
       "    &lt;body&gt;\n",
       "        &lt;script src=&quot;https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js&quot;&gt;&lt;/script&gt;\n",
       "        &lt;script&gt;\n",
       "            mermaid.initialize({ startOnLoad: true });\n",
       "        &lt;/script&gt;\n",
       " \n",
       "        &lt;div class=&quot;mermaid&quot;&gt;\n",
       "            graph LR\n",
       "    %% Input Layer\n",
       "    subgraph IL[Input Layer]\n",
       "        I1[x₁]\n",
       "        I2[x₂]\n",
       "    end\n",
       "\n",
       "    %% Hidden Layer with corrected numbering (top to bottom)\n",
       "    subgraph HL[Hidden Layer]\n",
       "        direction TB\n",
       "        H4[h₄&lt;br&gt;ReLU]\n",
       "        H3[h₃&lt;br&gt;ReLU]\n",
       "        H2[h₂&lt;br&gt;ReLU]\n",
       "        H1[h₁&lt;br&gt;ReLU]\n",
       "    end\n",
       "\n",
       "    %% Output Layer with corrected numbering (top to bottom)\n",
       "    subgraph OL[Output Layer]\n",
       "        direction TB\n",
       "        O2[y₂&lt;br&gt;Softmax]\n",
       "        O1[y₁&lt;br&gt;Softmax]\n",
       "    end\n",
       "\n",
       "    %% Connections from Input to Hidden Layer\n",
       "    I1 --&gt; H1\n",
       "    I1 --&gt; H2\n",
       "    I1 --&gt; H3\n",
       "    I1 --&gt; H4\n",
       "    I2 --&gt; H1\n",
       "    I2 --&gt; H2\n",
       "    I2 --&gt; H3\n",
       "    I2 --&gt; H4\n",
       "\n",
       "    %% Connections from Hidden to Output Layer\n",
       "    H1 --&gt; O1\n",
       "    H1 --&gt; O2\n",
       "    H2 --&gt; O1\n",
       "    H2 --&gt; O2\n",
       "    H3 --&gt; O1\n",
       "    H3 --&gt; O2\n",
       "    H4 --&gt; O1\n",
       "    H4 --&gt; O2\n",
       "\n",
       "    %% Annotations\n",
       "    classDef inputClass fill:#f9f,stroke:#333,stroke-width:2px\n",
       "    classDef hiddenClass fill:#bbf,stroke:#333,stroke-width:2px\n",
       "    classDef outputClass fill:#bfb,stroke:#333,stroke-width:2px\n",
       "    \n",
       "    class I1,I2 inputClass\n",
       "    class H1,H2,H3,H4 hiddenClass\n",
       "    class O1,O2 outputClass\n",
       "\n",
       "    %% Add annotations for more details\n",
       "    annInput[Input Features&lt;br&gt;2 nodes]\n",
       "    annHidden[Hidden Layer&lt;br&gt;4 nodes&lt;br&gt;ReLU Activation]\n",
       "    annOutput[Output Layer&lt;br&gt;2 nodes&lt;br&gt;Softmax Activation]\n",
       "\n",
       "    annInput -.-&gt; IL\n",
       "    annHidden -.-&gt; HL\n",
       "    annOutput -.-&gt; OL\n",
       "        &lt;/div&gt;\n",
       " \n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=\"100%\" height=\"850\"style=\"border:none !important;\" \"allowfullscreen\" \"webkitallowfullscreen\" \"mozallowfullscreen\"></iframe>"
      ],
      "text/plain": [
       "<nb_js_diagrammers.magics.JSDiagram at 0x109122190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%mermaid_magic -h 850\n",
    "graph LR\n",
    "    %% Input Layer\n",
    "    subgraph IL[Input Layer]\n",
    "        I1[x₁]\n",
    "        I2[x₂]\n",
    "    end\n",
    "\n",
    "    %% Hidden Layer with corrected numbering (top to bottom)\n",
    "    subgraph HL[Hidden Layer]\n",
    "        direction TB\n",
    "        H4[h₄<br>ReLU]\n",
    "        H3[h₃<br>ReLU]\n",
    "        H2[h₂<br>ReLU]\n",
    "        H1[h₁<br>ReLU]\n",
    "    end\n",
    "\n",
    "    %% Output Layer with corrected numbering (top to bottom)\n",
    "    subgraph OL[Output Layer]\n",
    "        direction TB\n",
    "        O2[y₂<br>Softmax]\n",
    "        O1[y₁<br>Softmax]\n",
    "    end\n",
    "\n",
    "    %% Connections from Input to Hidden Layer\n",
    "    I1 --> H1\n",
    "    I1 --> H2\n",
    "    I1 --> H3\n",
    "    I1 --> H4\n",
    "    I2 --> H1\n",
    "    I2 --> H2\n",
    "    I2 --> H3\n",
    "    I2 --> H4\n",
    "\n",
    "    %% Connections from Hidden to Output Layer\n",
    "    H1 --> O1\n",
    "    H1 --> O2\n",
    "    H2 --> O1\n",
    "    H2 --> O2\n",
    "    H3 --> O1\n",
    "    H3 --> O2\n",
    "    H4 --> O1\n",
    "    H4 --> O2\n",
    "\n",
    "    %% Annotations\n",
    "    classDef inputClass fill:#f9f,stroke:#333,stroke-width:2px\n",
    "    classDef hiddenClass fill:#bbf,stroke:#333,stroke-width:2px\n",
    "    classDef outputClass fill:#bfb,stroke:#333,stroke-width:2px\n",
    "    \n",
    "    class I1,I2 inputClass\n",
    "    class H1,H2,H3,H4 hiddenClass\n",
    "    class O1,O2 outputClass\n",
    "\n",
    "    %% Add annotations for more details\n",
    "    annInput[Input Features<br>2 nodes]\n",
    "    annHidden[Hidden Layer<br>4 nodes<br>ReLU Activation]\n",
    "    annOutput[Output Layer<br>2 nodes<br>Softmax Activation]\n",
    "\n",
    "    annInput -.-> IL\n",
    "    annHidden -.-> HL\n",
    "    annOutput -.-> OL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedacffb-0f5b-4aca-acf0-b21c241212d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde4ab45-7ce8-41ce-8f65-95bc7e036f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_sample_data(n_samples=6):\n",
    "    \"\"\"\n",
    "    Generate random sample data with 2 features\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        \n",
    "    Returns:\n",
    "        X: Input features array of shape (n_samples, 2)\n",
    "    \"\"\"\n",
    "    X = np.random.randint(1, 11, size=(n_samples, 2))\n",
    "    return X\n",
    "\n",
    "def initialize_weights(input_size=2, hidden_size=4, output_size=2):\n",
    "    \"\"\"\n",
    "    Initialize weights and biases for the neural network\n",
    "    \n",
    "    Args:\n",
    "        input_size: Number of input features\n",
    "        hidden_size: Number of nodes in hidden layer\n",
    "        output_size: Number of output nodes\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing weights and biases\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        # Input to hidden layer weights\n",
    "        'W1': np.random.randn(input_size, hidden_size) * 0.01,\n",
    "        \n",
    "        # Hidden layer bias\n",
    "        'b1': np.zeros((1, hidden_size)),\n",
    "        # Hidden to output layer weights\n",
    "        'W2': np.random.randn(hidden_size, output_size) * 0.01,\n",
    "        # Output layer bias\n",
    "        'b2': np.zeros((1, output_size))\n",
    "    }\n",
    "    return params\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    \"\"\"\n",
    "    ReLU activation function\n",
    "    \n",
    "    Args:\n",
    "        z: Input to the activation function\n",
    "        \n",
    "    Returns:\n",
    "        ReLU of input: max(0, z)\n",
    "    \"\"\"\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Softmax activation function\n",
    "    \n",
    "    Args:\n",
    "        z: Input to the activation function, shape (batch_size, n_classes)\n",
    "        \n",
    "    Returns:\n",
    "        Softmax probabilities with same shape as input\n",
    "    \"\"\"\n",
    "    # Subtract max for numerical stability (prevents overflow)\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def forward_propagation(X, params):\n",
    "    \"\"\"\n",
    "    Perform forward propagation through the network\n",
    "    \n",
    "    Args:\n",
    "        X: Input features array\n",
    "        params: Dictionary containing weights and biases\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing activations and intermediate values\n",
    "    \"\"\"\n",
    "    # Extract weights and biases\n",
    "    W1, b1 = params['W1'], params['b1']\n",
    "    W2, b2 = params['W2'], params['b2']\n",
    "    \n",
    "    # Hidden layer calculations\n",
    "    Z1 = np.dot(X, W1) + b1           # Linear transformation\n",
    "    A1 = relu(Z1)                     # ReLU Activation\n",
    "    \n",
    "    # Output layer calculations\n",
    "    Z2 = np.dot(A1, W2) + b2  # Linear transformation\n",
    "    A2 = softmax(Z2)        # Softmax activation\n",
    "    \n",
    "    cache = {\n",
    "        'Z1': Z1, 'A1': A1,\n",
    "        'Z2': Z2, 'A2': A2\n",
    "    }\n",
    "    \n",
    "    return cache\n",
    "\n",
    "\n",
    "def print_step_by_step(X, params, cache):\n",
    "    \"\"\"\n",
    "    Print detailed step-by-step calculations for feed forward neural network\n",
    "    \n",
    "    Args:\n",
    "        X: Input features\n",
    "        params: Network parameters\n",
    "        cache: Activation values from forward propagation\n",
    "    \"\"\"\n",
    "    print(\"\\nStep-by-Step Calculations:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Input layer\n",
    "    print(\"\\nInput Layer:\")\n",
    "    print(f\"Input features (X):\\n\\n{X}\")\n",
    "    \n",
    "    # Hidden layer calculations\n",
    "    print(\"\\nHidden Layer Calculations:\")\n",
    "    print(f\"Weights (W1):\\n\\n{params['W1']}\")\n",
    "    print(f\"Biases (b1):\\n\\n{params['b1']}\")\n",
    "    \n",
    "    print(f\"Weights (W1) shape: {params['W1'].shape}\")\n",
    "    print(f\"Biases (b1) shape: {params['b1'].shape}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Linear transformation (Z1 = X·W1 + b1):\\n\\n{cache['Z1']}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Activation (A1 = relu(Z1)):\\n\\n{cache['A1']}\")\n",
    "    print()\n",
    "    \n",
    "    # Output layer calculations\n",
    "    print(\"\\nOutput Layer Calculations:\")\n",
    "    print(f\"Weights (W2):\\n\\n{params['W2']}\")\n",
    "    print(f\"Biases (b2):\\n\\n{params['b2']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Linear transformation (Z2 = A1·W2 + b2):\\n\\n{cache['Z2']}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Final Output (A2 = softmax(Z2)):\\n\\n{cache['A2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b613ced-a4b4-46c3-a8a7-600f63e0aa26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_target_data(n_samples=6, n_classes=2):\n",
    "    \"\"\"\n",
    "    Generate target variables for classification\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples\n",
    "        n_classes: Number of classes (output nodes)\n",
    "        \n",
    "    Returns:\n",
    "        y: One-hot encoded target variables\n",
    "    \"\"\"\n",
    "    # Generate random class labels (0 to n_classes-1)\n",
    "    y_labels = np.random.randint(0, n_classes, size=n_samples)\n",
    "    \n",
    "    # Convert to one-hot encoding\n",
    "    y = np.zeros((n_samples, n_classes))\n",
    "    y[np.arange(n_samples), y_labels] = 1\n",
    "    return y, y_labels\n",
    "\n",
    "def predict(X, params):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained network\n",
    "    \n",
    "    Args:\n",
    "        X: Input features\n",
    "        params: Network parameters\n",
    "        \n",
    "    Returns:\n",
    "        predictions: Predicted class labels\n",
    "        probabilities: Class probabilities\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    cache = forward_propagation(X, params)\n",
    "    \n",
    "    # Get probabilities from output layer\n",
    "    probabilities = cache['A2']\n",
    "    \n",
    "    # Get predicted class (argmax of probabilities)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions, y_true, probabilities):\n",
    "    \"\"\"\n",
    "    Print evaluation metrics for the predictions\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted class labels\n",
    "        y_true: True class labels\n",
    "        probabilities: Predicted probabilities\n",
    "    \"\"\"\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nPredicted Probabilities:\")\n",
    "    print(probabilities)\n",
    "    print(\"\\nPredicted Classes:\", predictions)\n",
    "    print(\"True Classes:\", y_true)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(predictions == y_true)\n",
    "    print(f\"\\nAccuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1056702f-8dfc-41c8-9c08-29382a37ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "# np.random.seed(1010)\n",
    "X = generate_sample_data()\n",
    "\n",
    "# Initialize network parameters\n",
    "params = initialize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178860dd-8206-4cb8-a8ef-5a6d51d4cc41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform forward propagation\n",
    "cache = forward_propagation(X, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9334ac40-60e6-4f50-8d22-b07a4a5c3ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step-by-Step Calculations:\n",
      "--------------------------------------------------\n",
      "\n",
      "Input Layer:\n",
      "Input features (X):\n",
      "\n",
      "[[10  2]\n",
      " [ 8  2]\n",
      " [ 6  1]\n",
      " [ 2  1]\n",
      " [10  2]\n",
      " [ 4  9]]\n",
      "\n",
      "Hidden Layer Calculations:\n",
      "Weights (W1):\n",
      "\n",
      "[[ 0.00248006  0.00298038  0.00283817 -0.00471223]\n",
      " [ 0.00952028 -0.00638603 -0.01260901 -0.00558495]]\n",
      "Biases (b1):\n",
      "\n",
      "[[0. 0. 0. 0.]]\n",
      "Weights (W1) shape: (2, 4)\n",
      "Biases (b1) shape: (1, 4)\n",
      "\n",
      "Linear transformation (Z1 = X·W1 + b1):\n",
      "\n",
      "[[ 0.04384115  0.01703171  0.00316365 -0.05829219]\n",
      " [ 0.03888103  0.01107096 -0.00251268 -0.04886774]\n",
      " [ 0.02440063  0.01149623  0.00441999 -0.03385833]\n",
      " [ 0.0144804  -0.00042528 -0.00693267 -0.01500941]\n",
      " [ 0.04384115  0.01703171  0.00316365 -0.05829219]\n",
      " [ 0.09560276 -0.04555278 -0.1021284  -0.06911348]]\n",
      "\n",
      "Activation (A1 = relu(Z1)):\n",
      "\n",
      "[[0.04384115 0.01703171 0.00316365 0.        ]\n",
      " [0.03888103 0.01107096 0.         0.        ]\n",
      " [0.02440063 0.01149623 0.00441999 0.        ]\n",
      " [0.0144804  0.         0.         0.        ]\n",
      " [0.04384115 0.01703171 0.00316365 0.        ]\n",
      " [0.09560276 0.         0.         0.        ]]\n",
      "\n",
      "\n",
      "Output Layer Calculations:\n",
      "Weights (W2):\n",
      "\n",
      "[[ 0.00172743 -0.00055948]\n",
      " [-0.01432228 -0.00302672]\n",
      " [-0.00584554  0.00796938]\n",
      " [-0.00786239 -0.01361172]]\n",
      "Biases (b2):\n",
      "\n",
      "[[0. 0.]]\n",
      "\n",
      "Linear transformation (Z2 = A1·W2 + b2):\n",
      "\n",
      "[[-1.86693514e-04 -5.08659965e-05]\n",
      " [-9.13969412e-05 -5.52617035e-05]\n",
      " [-1.48339038e-04 -1.32228794e-05]\n",
      " [ 2.50139407e-05 -8.10143668e-06]\n",
      " [-1.86693514e-04 -5.08659965e-05]\n",
      " [ 1.65147521e-04 -5.34874613e-05]]\n",
      "\n",
      "Final Output (A2 = softmax(Z2)):\n",
      "\n",
      "[[0.49996604 0.50003396]\n",
      " [0.49999097 0.50000903]\n",
      " [0.49996622 0.50003378]\n",
      " [0.50000828 0.49999172]\n",
      " [0.49996604 0.50003396]\n",
      " [0.50005466 0.49994534]]\n"
     ]
    }
   ],
   "source": [
    "# Print detailed calculations\n",
    "print_step_by_step(X, params, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eab4fc7-d5e7-48bd-9097-f260ae4d5c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "Predicted Probabilities:\n",
      "[[0.49996604 0.50003396]\n",
      " [0.49999097 0.50000903]\n",
      " [0.49996622 0.50003378]\n",
      " [0.50000828 0.49999172]\n",
      " [0.49996604 0.50003396]\n",
      " [0.50005466 0.49994534]]\n",
      "\n",
      "Predicted Classes: [1 1 1 0 1 0]\n",
      "True Classes: [1 0 1 1 0 1]\n",
      "\n",
      "Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# Generate target variables\n",
    "y, y_true = generate_target_data()\n",
    "\n",
    "# Make predictions\n",
    "predictions, probabilities = predict(X, params)\n",
    "\n",
    "# Evaluate predictions\n",
    "evaluate_predictions(predictions, y_true, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe5630-74bc-40a9-bf77-78f7be307354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a042bd-619e-486b-a5ca-433005b4614d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
